{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 2020883272319796631]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]='1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 라이브러리 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import keras\n",
    "# 케라스 모델 생성 라이브러리\n",
    "from keras import models\n",
    "# 레이어 생성 라이브러리 (Dense: 입출력 연결)\n",
    "from keras import layers\n",
    "# 케라스 샘플데이터[mnist] 라이브러리 불러오기\n",
    "from keras.datasets import mnist\n",
    "# numpy 라이브러리\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "# 케라스 카테고리 라이브러리\n",
    "from keras.utils import to_categorical\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "# 시각화 라이브러리\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 훈련데이터 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = '../images/mnist/trainingSet/'\n",
    "train_folder_list = array(os.listdir(TRAIN_DIR))\n",
    "train_folder_list\n",
    "\n",
    "IMG_SIZE = 28\n",
    "train_images=[]\n",
    "train_labels=[]\n",
    "for index in range(len(train_folder_list)):\n",
    "    path = os.path.join(TRAIN_DIR, train_folder_list[index])\n",
    "    path = path + '/'\n",
    "    img_list = os.listdir(path)\n",
    "    for img in img_list:\n",
    "        img_path = os.path.join(path, img)\n",
    "        try:\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            new_img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "            train_images.append(new_img)\n",
    "            train_labels.append(index)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array(train_images).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf = pd.DataFrame(train_images[41999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf.to_csv(\"./number.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 테스트 데이터 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DIR = '../images/mnist/testSet/'\n",
    "test_folder_list = array(os.listdir(TEST_DIR))\n",
    "test_folder_list\n",
    "\n",
    "test_images=[]\n",
    "test_labels=[]\n",
    "for index in range(len(test_folder_list)):\n",
    "    path = os.path.join(TEST_DIR, test_folder_list[index])\n",
    "    path = path + '/'\n",
    "    img_list = os.listdir(path)\n",
    "    for img in img_list:\n",
    "        img_path = os.path.join(path, img)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        new_img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "        test_images.append(new_img)\n",
    "        test_labels.append(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 데이터셋 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = array(train_images)\n",
    "train_labels = array(train_labels)\n",
    "test_images = array(test_images)\n",
    "test_labels = array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape :  (42000, 28, 28) (42000,)\n",
      "Testing data shape :  (200, 28, 28) (200,)\n"
     ]
    }
   ],
   "source": [
    "print('Training data shape : ', train_images.shape, train_labels.shape)\n",
    "print('Testing data shape : ', test_images.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of outputs :  10\n",
      "Output classes :  [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    " \n",
    "# 훈련데이터의 답지분류 범위 정의\n",
    "classes = np.unique(train_labels)\n",
    "nClasses = len(classes)\n",
    "print('Total number of outputs : ', nClasses)\n",
    "print('Output classes : ', classes)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'label : 2')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 훈련/데이터 데이터 시각화\n",
    "plt.figure(figsize=[7,5])\n",
    "plt.subplot(121)\n",
    "plt.imshow(train_images[0], cmap='gray')\n",
    "plt.title(\"label : {}\".format(train_labels[0]))\n",
    "plt.subplot(122)\n",
    "plt.imshow(test_images[42], cmap='gray')\n",
    "plt.title(\"label : {}\".format(test_labels[42]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1. 이미지(28*28) 매트릭스 변환 (w,h,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 28, 28)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_images.reshape(len(train_images), IMG_SIZE,IMG_SIZE,1)\n",
    "test_data = test_images.reshape(len(test_images), IMG_SIZE,IMG_SIZE,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 28, 28)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 28, 28, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  1,  5,  0, 12,  0, 16,  0,  0,  4,  0,\n",
       "        2,  8,  3,  0,  4,  8,  0,  0,  0,  0,  0], dtype=uint8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2. float 타입변환 및 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.astype('float')\n",
    "test_data = test_data.astype('float')\n",
    "\n",
    "train_data /= 255\n",
    "test_data /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-3. 답지 분류형으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original label 0 :  2\n",
      "After conversion to categorical ( one-hot ) :  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Change the labels from integer to categorical data\n",
    "train_labels_one_hot = to_categorical(train_labels)\n",
    "test_labels_one_hot = to_categorical(test_labels)\n",
    " \n",
    "# Display the change for category label using one-hot encoding\n",
    "print('Original label 0 : ', train_labels[10000])\n",
    "print('After conversion to categorical ( one-hot ) : ', train_labels_one_hot[10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argmax(train_labels_one_hot[10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData_features,\\\n",
    "validData_features,\\\n",
    "trainingData_label,\\\n",
    "validData_label=\\\n",
    "train_test_split(train_data, \n",
    "                 train_labels_one_hot, \n",
    "                 test_size = 0.2, \n",
    "                 random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# oe_label = OneHotEncoder()\n",
    "\n",
    "# train_labels_t = train_labels.reshape(-1,1)\n",
    "# test_labels_t = test_labels.reshape(-1,1)\n",
    "# oe_label.fit(train_labels_t)\n",
    "# train_labels_one_hot = oe_label.transform(train_labels_t).toarray()\n",
    "# test_labels_one_hot = oe_label.transform(test_labels_t).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original label 0 :  0\n",
      "After conversion to categorical ( one-hot ) :  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Display the change for category label using one-hot encoding\n",
    "print('Original label 0 : ', train_labels[2])\n",
    "print('After conversion to categorical ( one-hot ) : ', train_labels_one_hot[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 케라스 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 6280      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                90        \n",
      "=================================================================\n",
      "Total params: 6,370\n",
      "Trainable params: 6,370\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 입력데이터 형태\n",
    "modelDim = trainingData_features[0].shape\n",
    "\n",
    "# 층 누적 기본형태\n",
    "model = Sequential()\n",
    "\n",
    "# 신경망의 첫 번째 레이어에서 입력 데이터 크기를 정의해야 합니다.\n",
    "model.add(Flatten(input_shape=modelDim))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(nClasses, activation='softmax'))\n",
    "\n",
    "# model.summary()를 통해 모델을 살펴보세요.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelDim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kopo\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1000)              3137000   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 3,156,098\n",
      "Trainable params: 3,156,098\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 입력데이터 형태\n",
    "modelDim = trainingData_features[0].shape\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1), padding='same',\n",
    "                 activation='relu',\n",
    "                 input_shape=modelDim))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Conv2D(64, (2, 2), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nClasses, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 모델 시각화\n",
    "# from keras.utils import plot_model\n",
    "# plot_model(model, to_file='model_plot.png', \n",
    "#            show_shapes=True, \n",
    "#            show_layer_names=True)\n",
    "# from IPython.display import Image\n",
    "# Image(retina=True, filename='model_plot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 케라스모델 훈련방법 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequatial 방싱 케라스모델\n",
    "# 손실함수(LOSS): 훈련동안 최소화될 값 지표 (mse, categorical_crossentropy)\n",
    "# 손실함수를 기반으로 Neural Net 업데이터 결정 (mse, mae, accuracy)\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.python.client import device_lib\n",
    "# print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 소요시간:  5.8534000004328846e-05\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "start = timeit.default_timer()\n",
    "\n",
    "# 실행 코드\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print(\"총 소요시간: \", stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'session' in locals() and session is not None:\n",
    "    print('Close interactive session')\n",
    "    session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kopo\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 33600 samples, validate on 8400 samples\n",
      "WARNING:tensorflow:From C:\\Users\\kopo\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\callbacks\\tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\kopo\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\callbacks\\tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/10\n",
      "33600/33600 [==============================] - 103s 3ms/step - loss: 0.1787 - accuracy: 0.9432 - val_loss: 0.0903 - val_accuracy: 0.9733\n",
      "WARNING:tensorflow:From C:\\Users\\kopo\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\callbacks\\tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n",
      "Epoch 2/10\n",
      "   32/33600 [..............................] - ETA: 1:17 - loss: 0.0578 - accuracy: 0.96"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kopo\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_accuracy,loss,accuracy\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33600/33600 [==============================] - 104s 3ms/step - loss: 0.0645 - accuracy: 0.9791 - val_loss: 0.0681 - val_accuracy: 0.9800\n",
      "Epoch 3/10\n",
      "33600/33600 [==============================] - 105s 3ms/step - loss: 0.0482 - accuracy: 0.9848 - val_loss: 0.0561 - val_accuracy: 0.9844\n",
      "Epoch 4/10\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0411 - accuracy: 0.9862 - val_loss: 0.0541 - val_accuracy: 0.9850\n",
      "Epoch 5/10\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0356 - accuracy: 0.9883 - val_loss: 0.0409 - val_accuracy: 0.9877\n",
      "Epoch 6/10\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0283 - accuracy: 0.9912 - val_loss: 0.0394 - val_accuracy: 0.9888\n",
      "Epoch 7/10\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0228 - accuracy: 0.9927 - val_loss: 0.0553 - val_accuracy: 0.9856\n",
      "Epoch 8/10\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0257 - accuracy: 0.9914 - val_loss: 0.0511 - val_accuracy: 0.9867\n",
      "Epoch 9/10\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0198 - accuracy: 0.9936 - val_loss: 0.0523 - val_accuracy: 0.9881\n",
      "Epoch 10/10\n",
      "33600/33600 [==============================] - 102s 3ms/step - loss: 0.0205 - accuracy: 0.9931 - val_loss: 0.0503 - val_accuracy: 0.9881\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "date = now.strftime(\"%Y-%m-%d_%H%M\")\n",
    "save_dir = \"./logs_{}\".format(date)\n",
    "\n",
    "callbacks = [\n",
    "    \n",
    "    keras.callbacks.TensorBoard(\n",
    "    log_dir = save_dir,\n",
    "    write_graph=True,\n",
    "    write_images=True)\n",
    "    ,  \n",
    "    keras.callbacks.EarlyStopping(\n",
    "    monitor = 'val_acc', patience=10,\n",
    "    )\n",
    "]\n",
    "\n",
    "# 모델을 32개의 샘플씩 미니 배치를 만들어 20번의 에포크 동안 훈련\n",
    "history = model.fit(trainingData_features, trainingData_label, \n",
    "                    validation_data=(validData_features,validData_label),\n",
    "                    batch_size=32,\n",
    "                    epochs=10,\n",
    "                    callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.039448</td>\n",
       "      <td>0.988810</td>\n",
       "      <td>0.028321</td>\n",
       "      <td>0.991250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.055274</td>\n",
       "      <td>0.985595</td>\n",
       "      <td>0.022775</td>\n",
       "      <td>0.992679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.051082</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.025709</td>\n",
       "      <td>0.991429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.052304</td>\n",
       "      <td>0.988095</td>\n",
       "      <td>0.019815</td>\n",
       "      <td>0.993571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.050284</td>\n",
       "      <td>0.988095</td>\n",
       "      <td>0.020539</td>\n",
       "      <td>0.993095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   val_loss  val_accuracy      loss  accuracy\n",
       "5  0.039448      0.988810  0.028321  0.991250\n",
       "6  0.055274      0.985595  0.022775  0.992679\n",
       "7  0.051082      0.986667  0.025709  0.991429\n",
       "8  0.052304      0.988095  0.019815  0.993571\n",
       "9  0.050284      0.988095  0.020539  0.993095"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. 모델 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 495us/step\n",
      "0.08547249073661078 0.9900000095367432\n"
     ]
    }
   ],
   "source": [
    "# verbose: 정보표시 레벨 (0,1)\n",
    "test_loss, test_acc = model.evaluate(test_data, \n",
    "                                     test_labels_one_hot)\n",
    "print(test_loss, test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. 훈련내용 확인하기 (Tensorboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. 예측 및 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x296379adeb8>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "prd_images = []\n",
    "imgpah=\"../images/mnist/testSet/5/img_24.jpg\"\n",
    "img = cv2.imread(imgpah, cv2.IMREAD_GRAYSCALE)\n",
    "prd_images.append(img)\n",
    "prd_images=array(prd_images)\n",
    "\n",
    "plt.imshow(img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = prd_images.reshape(len(prd_images) , IMG_SIZE, IMG_SIZE,1)\n",
    "test_data = test_data.astype('float')\n",
    "test_data /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the most likely class\n",
    "label_pred = model.predict(test_data[[0],:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.6898622e-14, 1.1505622e-16, 1.8752314e-20, 8.7779442e-13,\n",
       "        4.9868306e-14, 1.0000000e+00, 8.0197852e-14, 2.2245969e-15,\n",
       "        3.5822840e-12, 9.5670943e-11]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(label_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다른모델 생성 (과적합 회피)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_3 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 8)                 6280      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                90        \n",
      "=================================================================\n",
      "Total params: 6,370\n",
      "Trainable params: 6,370\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "# 입력데이터 형태\n",
    "modelDim = trainingData_features[0].shape\n",
    "\n",
    "# 층 누적 기본형태\n",
    "model = Sequential()\n",
    "\n",
    "# 신경망의 첫 번째 레이어에서 입력 데이터 크기를 정의해야 합니다.\n",
    "model.add(Flatten(input_shape=modelDim))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nClasses, activation='softmax'))\n",
    "\n",
    "# model.summary()를 통해 모델을 살펴보세요.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [실습]. fashion_mnist 데이터를 활용하여 신경망구조를 생성하고 훈련시켜보세요\n",
    "### keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [실습] 제공된 cat_dog 이미지 파일을 학습 후 cat / dog 이미지 분류기를 생성하세요\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 9us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 45s 2us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 3s 1us/step\n"
     ]
    }
   ],
   "source": [
    "# 미리 섞여진 fashion-mnist 의 학습 데이터와 테스트 데이터 로드\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2962409e518>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras import backend as K\n",
    "\n",
    "# K.clear_session()\n",
    "\n",
    "# from numba import cuda\n",
    "# cuda.select_device(0)\n",
    "# cuda.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
